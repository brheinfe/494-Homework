{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM57vJ53WLRIfXlVtMdUQgO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brheinfe/494-Homework/blob/main/Homework1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MAE 494 Homework 1**<br>\n",
        "**Problem 1**<br>\n",
        "Solve the following problem using Python SciPy.optimize or JuMP.\n",
        "Please attach your code and results. Specify your initial guesses of\n",
        "the solution. If you change your initial guess, do you find different\n",
        "solutions? (30 points)<br>\n",
        "minimize: $(x_1 − x_2)^2 + (x_2 + x_3 − 2)^2 + (x_4 − 1)^2 + (x_5 − 1)^2$<br>\n",
        "subject to: $x_1 + 3x_2 = 0$<br>\n",
        "$x_3 + x_4 − 2x_5 = 0$<br>\n",
        "$x_2 − x_5 = 0$<br>\n",
        "$− 10 ≤ x_i ≤ 10, i = 1, . . . , 5$<br><br><br>\n",
        "SciPy User Guide (For my own use): https://docs.scipy.org/doc/scipy/tutorial/optimize.html#"
      ],
      "metadata": {
        "id": "7biOrQP83xKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.optimize as spopt\n",
        "x0 = [-30,50,-200,40,16]\n",
        "def f(x):\n",
        "  return (x[0]-x[1])**2+(x[1]+x[2]-2)**2+(x[3]-1)**2+(x[4]-1)**2\n",
        "from scipy.optimize import LinearConstraint\n",
        "linconst = LinearConstraint([[1,3,0,0,0],[0,0,1,1,-2],[0,1,0,0,-1]],[0,0,0],[0,0,0])\n",
        "from scipy.optimize import Bounds\n",
        "bounds = Bounds(-10,10)\n",
        "output = spopt.minimize(f,x0,constraints=linconst,bounds=bounds)\n",
        "print(\"Initial Guesses:\",x0)\n",
        "print(\"x =\",output.x)\n",
        "print(\"Minimized Value:\",f(output.x))"
      ],
      "metadata": {
        "id": "qro1nvyT32hX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f16fdf8c-f408-44ae-be7f-46475dc9dff3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Guesses: [-30, 50, -200, 40, 16]\n",
            "x = [-0.76744185  0.25581395  0.62790698 -0.11627908  0.25581395]\n",
            "Minimized Value: 4.093023255813954\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results of this minimization are shown above. Changing the initial guess does not result in a change in the solution, even when the initial guess is outside the problem bounds. I think it would change if the bounds were removed. I will test this theory below:"
      ],
      "metadata": {
        "id": "V9yJS022PAsp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.optimize as spopt\n",
        "x0 = [-30,50,-200,40,16]\n",
        "def f(x):\n",
        "  return (x[0]-x[1])**2+(x[1]+x[2]-2)**2+(x[3]-1)**2+(x[4]-1)**2\n",
        "from scipy.optimize import LinearConstraint\n",
        "linconst = LinearConstraint([[1,3,0,0,0],[0,0,1,1,-2],[0,1,0,0,-1]],[0,0,0],[0,0,0])\n",
        "#from scipy.optimize import Bounds\n",
        "#bounds = Bounds(-10,10)\n",
        "#output = spopt.minimize(f,x0,constraints=linconst,bounds=bounds)\n",
        "output = spopt.minimize(f,x0,constraints=linconst)\n",
        "print(\"Initial Guesses:\",x0)\n",
        "print(\"x =\",output.x)\n",
        "print(\"Minimized Value:\",f(output.x))"
      ],
      "metadata": {
        "id": "A0F_WA33Pd-l",
        "outputId": "4e1d54c8-de98-4e84-85d2-5bceff63fc98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Guesses: [-30, 50, -200, 40, 16]\n",
            "x = [-0.76744186  0.25581395  0.62790697 -0.11627906  0.25581395]\n",
            "Minimized Value: 4.093023255813954\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From this block of code, we can see that my hypothesis was incorrect. It would appear this function minimizes to the same value, regardless of the boundary conditions.<br><br>\n",
        "**Problem 2**<br>\n",
        "Let $x$ and $b ∈ R^n$ be vectors and $A ∈ R^{n×n}$ be a square matrix. Define\n",
        "$f : R^n → R$ as $f (x) = b^T x + x^T Ax$. (20 points)<br>\n",
        "(a) What are the gradient and Hessian of $f (x)$ with respect to $x$?<br>\n",
        "(b) Derive the first- and second-order Taylor’s approximations of $f (x)$\n",
        "at $x = 0$. Are these approximations exact?<br><br>\n",
        "(a) $$f(x) = b^Tx+x^TAx$$<br>\n",
        "$$f(x) =\n",
        "\\left[\\begin{array}{cc}\n",
        "b_1 & b_2 & b_3 & ... & b_n\n",
        "\\end{array}\\right]\n",
        "\\left[\\begin{array}{cc}\n",
        "x_1 \\\\ x_2 \\\\ x_3 \\\\ ⋮ \\\\ x_n\n",
        "\\end{array}\\right]+\n",
        "\\left[\\begin{array}{cc}\n",
        "x_1 & x_2 & x_3 & ... & x_n\n",
        "\\end{array}\\right]\n",
        "\\left[\\begin{array}{cc}\n",
        "A_{1,1} & A_{1,2} & A_{1,3} & ... & A_{1,n}\\\\\n",
        "A_{2,1} & A_{2,2} & A_{2,3} & ... & A_{2,n}\\\\\n",
        "A_{3,1} & A_{3,2} & A_{3,3} & ... & A_{3,n}\\\\\n",
        "A_{3,1} & A_{3,2} & A_{3,3} & ... & A_{3,n}\\\\\n",
        "⋮ & ⋮ & ⋮ & ⋱ & ⋮\\\\\n",
        "A_{n,1} & A_{n,2} & A_{n,3} & ... & A_{n,n}\\\\\n",
        "\\end{array}\\right]\n",
        "\\left[\\begin{array}{cc}\n",
        "x_1 \\\\ x_2 \\\\ x_3 \\\\ ⋮ \\\\ x_n\n",
        "\\end{array}\\right]\n",
        "$$<br>\n",
        "\n",
        "$$f(x) = (b_1x_1+b_2x_2+b_3x_3+...+b_nx_n)+\n",
        "\\left[\\begin{array}{cc}\n",
        "\\sum_{i=1}^n A_{i,1}x_1 & \\sum_{i=1}^n A_{i,2}x_2 & \\sum_{i=1}^n A_{i,3}x_3 & ... & \\sum_{i=1}^n A_{i,n}x_n\n",
        "\\end{array}\\right]\n",
        "\\left[\\begin{array}{cc}\n",
        "x_1 \\\\ x_2 \\\\ x_3 \\\\ ⋮ \\\\ x_n\n",
        "\\end{array}\\right]\n",
        "$$<br>\n",
        "\n",
        "$$f(x) = \\sum_{i=1}^n b_ix_i+(x_1\\sum_{i=1}^n A_{i,1}x_1+x_2\\sum_{i=1}^n A_{i,2}x_2+x_3\\sum_{i=1}^n A_{i,3}x_3+...+x_n\\sum_{i=1}^n A_{i,n}x_n)\n",
        "$$<br>\n",
        "\n",
        "$$f(x) = \\sum_{i=1}^n b_ix_i+\\sum_{j=1}^n (x_j\\sum_{i=1}^n A_{i,j}x_j)\n",
        "$$<br>\n",
        "$\n",
        "\\therefore \\boxed{f'(x) = b + Ax + A^Tx}\n",
        "$ (Gradient)<br>\n",
        "$\n",
        "\\therefore \\boxed{f''(x) = A+A^T}\n",
        "$ (Hessian)<br><br>\n",
        "(b)\n",
        "$$\n",
        "T_1 = f(x_0)+f'(x_0)(x-x_0)\n",
        "$$<br>\n",
        "$$\n",
        "T_1 = f(0) + f'(0)(x-0)\n",
        "$$<br>\n",
        "$$\n",
        "T_1 = 0 + (b)(x)\n",
        "$$<br>\n",
        "$$\n",
        "\\boxed{T_1 = b^Tx}\n",
        "$$<br>\n",
        "$$\n",
        "T_2 = f(x_0)+f'(x_0)(x-x_0)+\\frac{1}{2}f''(x_0)(x-x_0)^2\n",
        "$$<br>\n",
        "$$\n",
        "T_2 = f(0) + f'(0)(x-0)+\\frac{1}{2}f''(0)(x-0)^2\n",
        "$$<br>\n",
        "$$\n",
        "T_2 = 0 + (b)(x) + \\frac{1}{2}(A+A^T)(x^2)\n",
        "$$<br>\n",
        "$$\n",
        "T_2 = b^Tx+\\frac{1}{2}(x^TAx+x^TA^Tx)\n",
        "$$<br>\n",
        "$$\n",
        "\\boxed{T_2 = b^Tx+x^TAx}\n",
        "$$"
      ],
      "metadata": {
        "id": "_fKQJ8AoPz8c"
      }
    }
  ]
}